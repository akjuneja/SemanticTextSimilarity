{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17190062",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6483,
     "status": "ok",
     "timestamp": 1647024041007,
     "user": {
      "displayName": "Faria Alam",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgA-IA0pDrCGKBsIUIuXVLu5X2mFDhecwjQ6LIp=s64",
      "userId": "01141680939008758463"
     },
     "user_tz": -60
    },
    "id": "17190062",
    "outputId": "4c43e359-7873-4a2b-e9cf-37e1a55f1932"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213550e",
   "metadata": {
    "id": "6213550e"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import stats\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "from utils_task3 import *\n",
    "\n",
    "#for reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gvrk1CBGmxKQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2846,
     "status": "ok",
     "timestamp": 1647024050398,
     "user": {
      "displayName": "Faria Alam",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgA-IA0pDrCGKBsIUIuXVLu5X2mFDhecwjQ6LIp=s64",
      "userId": "01141680939008758463"
     },
     "user_tz": -60
    },
    "id": "Gvrk1CBGmxKQ",
    "outputId": "6f1a0312-7872-4694-9cf6-3259801c0d15"
   },
   "outputs": [],
   "source": [
    "#load the data and process it\n",
    "train_data, validation_data, test_data = get_data()\n",
    "processed_train_data = process_data(train_data)\n",
    "processed_validation_data = process_data(validation_data)\n",
    "processed_test_data = process_data(test_data)\n",
    "\n",
    "#make the train, validation, test\n",
    "train_data_loader = DataLoader(processed_train_data, batch_size=32, shuffle=True)\n",
    "validation_data_loader = DataLoader(processed_validation_data, batch_size=64, shuffle=True)\n",
    "test_data_loader = DataLoader(processed_test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wBN-2xG1myar",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14946,
     "status": "ok",
     "timestamp": 1647024065337,
     "user": {
      "displayName": "Faria Alam",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgA-IA0pDrCGKBsIUIuXVLu5X2mFDhecwjQ6LIp=s64",
      "userId": "01141680939008758463"
     },
     "user_tz": -60
    },
    "id": "wBN-2xG1myar",
    "outputId": "44d433f3-f230-4e50-f67e-4ddb861a26bc"
   },
   "outputs": [],
   "source": [
    "#select the gpu if it is available\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "\n",
    "#load the bert model, tokenizer and linear layer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertLinear()\n",
    "\n",
    "# take the model to the selected device\n",
    "model.to(device)\n",
    "\n",
    "#declare the optimizer with selected learning rate\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr = 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6RcCsJQm_I0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 547702,
     "status": "ok",
     "timestamp": 1647024613031,
     "user": {
      "displayName": "Faria Alam",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgA-IA0pDrCGKBsIUIuXVLu5X2mFDhecwjQ6LIp=s64",
      "userId": "01141680939008758463"
     },
     "user_tz": -60
    },
    "id": "p6RcCsJQm_I0",
    "outputId": "a221f203-60aa-4638-e831-a83363861347"
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "#for time detection\n",
    "start_time = datetime.now()\n",
    "_ = train(model, tokenizer, optimizer, epochs, train_data_loader, validation_data_loader, device) #starts the training process\n",
    "\n",
    "end_time = datetime.now()\n",
    "time_difference = end_time - start_time \n",
    "seconds = time_difference.total_seconds()\n",
    "minutes = seconds / 60\n",
    "epoch_minutes = minutes / epochs\n",
    "\n",
    "print('Total minutes to train : '+str(minutes))\n",
    "print('Average minutes per epoch : '+str(epoch_minutes))\n",
    "\n",
    "#loads the saved models\n",
    "model, tokenizer = load_models(device)\n",
    "test(model, tokenizer, test_data_loader, device) #test the \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lTtff-RHDUqS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23170,
     "status": "ok",
     "timestamp": 1647024636186,
     "user": {
      "displayName": "Faria Alam",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgA-IA0pDrCGKBsIUIuXVLu5X2mFDhecwjQ6LIp=s64",
      "userId": "01141680939008758463"
     },
     "user_tz": -60
    },
    "id": "lTtff-RHDUqS",
    "outputId": "34186c1f-942c-41cb-d896-c4d86e756ccb"
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "pretrained_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "trained_bert_linear_model, _ = load_models(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BXDzwNFsFPxz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7909,
     "status": "ok",
     "timestamp": 1647024644077,
     "user": {
      "displayName": "Faria Alam",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgA-IA0pDrCGKBsIUIuXVLu5X2mFDhecwjQ6LIp=s64",
      "userId": "01141680939008758463"
     },
     "user_tz": -60
    },
    "id": "BXDzwNFsFPxz",
    "outputId": "03beec0d-06d7-4cd5-8f04-bd1c158c801e"
   },
   "outputs": [],
   "source": [
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Szd3IRoeFZGc",
   "metadata": {
    "id": "Szd3IRoeFZGc"
   },
   "outputs": [],
   "source": [
    "from bertviz import head_view, model_view\n",
    "sentence = None\n",
    "for data in test_data_loader:\n",
    "  sentence = data[0][0]\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xpyW9TI6I51I",
   "metadata": {
    "id": "xpyW9TI6I51I"
   },
   "outputs": [],
   "source": [
    "sentence_a, sentence_b = sentence.split('[SEP]')\n",
    "sentence_a, sentence_b = sentence_a.strip(), sentence_b.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8uLKGuA9GQs0",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 39,
     "output_embedded_package_id": "1hub0ljc4mTTe4ygydPAGM_YSk2NkAsY4"
    },
    "id": "8uLKGuA9GQs0",
    "outputId": "2d787274-167e-4724-914d-13a228d58dd6"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']\n",
    "token_type_ids = inputs['token_type_ids']\n",
    "attention = pretrained_model(input_ids, token_type_ids=token_type_ids, output_attentions=True)[-1]\n",
    "sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "head_view(attention, tokens, sentence_b_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PQ5g9hCsLtEr",
   "metadata": {
    "colab": {
     "background_save": true,
     "output_embedded_package_id": "1RnAjN1THV6H8ItVvkLPKvr20J9cwaRE7"
    },
    "id": "PQ5g9hCsLtEr",
    "outputId": "fda38a46-46cb-4797-9fe7-0b253df2345c"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
    "input_ids = inputs['input_ids'].to('cuda')\n",
    "token_type_ids = inputs['token_type_ids'].to('cuda')\n",
    "attention = trained_bert_linear_model.bert(input_ids, token_type_ids=token_type_ids, output_attentions=True)[-1]\n",
    "sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "head_view(attention, tokens, sentence_b_start)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
